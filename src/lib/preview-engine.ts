import type { Pipeline, PreviewResult } from './pipeline';
import { DSLCompiler } from './dsl-compiler';
import { DuckDBManager } from './duckdb';

/**
 * é¢„è§ˆå¼•æ“ - æ‰§è¡Œ DSL é¢„è§ˆå¹¶ç”Ÿæˆå·®å¼‚åˆ†æ
 */
export class PreviewEngine {
  private duckdb: DuckDBManager;
  private compiler: DSLCompiler;
  private backupStack: Map<string, string[]> = new Map(); // æ•°æ®å¤‡ä»½æ ˆ

  constructor() {
    this.duckdb = new DuckDBManager();
    this.compiler = new DSLCompiler();
  }

  /**
   * å®‰å…¨åœ°å°†BigIntè½¬æ¢ä¸ºnumber
   */
  private safeToNumber(value: any): number {
    if (value !== undefined && value !== null) {
      return Number(value);
    }
    return 0;
  }

  /**
   * åˆå§‹åŒ–é¢„è§ˆå¼•æ“
   */
  async initialize(): Promise<void> {
    await this.duckdb.initialize();
  }

  /**
   * æ³¨å†Œæ•°æ®é›†
   */
  async registerDataset(name: string, data: any[]): Promise<void> {
    await this.duckdb.registerJSON(name, data);
  }

  /**
   * æ‰§è¡Œé¢„è§ˆåˆ†æ
   */
  async preview(pipeline: Pipeline, sampleSize = 2000): Promise<PreviewResult> {
    const startTime = Date.now();

    try {
      // æ¸…ç†æ‰€æœ‰ä¸´æ—¶è¡¨å’Œè§†å›¾ä»¥é¿å…åç§°å†²çª
      await this.cleanupTempTables();

      // è·å–åŸå§‹æ•°æ®ä¿¡æ¯
      const originalInfo = await this.duckdb.getTableInfo(pipeline.dataset);

      // ç¼–è¯‘å¹¶æ‰§è¡Œé¢„è§ˆ SQL
      const previewSQLs = this.compiler.compileForPreview(pipeline, sampleSize);

      try {
        await this.duckdb.executeSequence(previewSQLs);
        // ç‰©åŒ– RESULT ä»¥é¿å…éƒ¨åˆ†è§†å›¾åœ¨åç»­æŸ¥è¯¢ä¸­è§¦å‘ DuckDB å†…éƒ¨é”™è¯¯
        try {
          await this.duckdb.query('CREATE OR REPLACE TEMP TABLE RESULT AS SELECT * FROM RESULT');
        } catch (e) {
          // If RESULT already a table, this still replaces it. Ignore errors here.
        }
      } catch (error: any) {
        // å¦‚æœé‡åˆ°DuckDBå†…éƒ¨é”™è¯¯ï¼Œå°è¯•é‡æ–°åˆå§‹åŒ–å¹¶é‡è¯•
        if (error?.message?.includes('Could not find column index for table filter')) {
          console.warn('ğŸ”„ DuckDB internal error detected, attempting recovery...');

          // é‡æ–°åˆå§‹åŒ–DuckDB
          await this.duckdb.cleanup();
          await this.duckdb.initialize();

          // é‡æ–°æ³¨å†Œæ•°æ®é›† - éœ€è¦ä»å¤–éƒ¨ä¼ å…¥æ•°æ®
          // è¿™é‡Œæš‚æ—¶æŠ›å‡ºé”™è¯¯ï¼Œæç¤ºéœ€è¦é‡æ–°ä¸Šä¼ æ•°æ®
          throw new Error('Database state corrupted. Please refresh the page and re-upload your data.');
        }
        throw error;
      }

      // è·å–å¤„ç†åæ•°æ®ä¿¡æ¯
      const resultInfo = await this.duckdb.getTableInfo('RESULT');

      // ç”Ÿæˆè¯¦ç»†çš„å·®å¼‚åˆ†æ
      const summary = await this.generateSummary(pipeline, originalInfo.rowCount);
      const samples = await this.collectSamples(pipeline);
      const risks = await this.assessRisks(pipeline, originalInfo.rowCount, resultInfo.rowCount);

      const result: PreviewResult = {
        rowsBefore: originalInfo.rowCount,
        rowsAfter: resultInfo.rowCount,
        columnsModified: await this.getModifiedColumns(pipeline),
        summary,
        samples,
        risks,
      };

      console.log(`âœ… Preview completed in ${Date.now() - startTime}ms`);
      return result;
    } catch (error) {
      console.error('âŒ Preview failed:', error);
      throw error;
    }
  }

  /**
   * ç”Ÿæˆæ“ä½œæ‘˜è¦
   */
  private async generateSummary(pipeline: Pipeline, originalRows: number): Promise<PreviewResult['summary']> {
    const summary = { added: 0, removed: 0, modified: 0 };

    try {
      // è®¡ç®—è¡Œæ•°å˜åŒ– - å¤„ç†BigIntè½¬æ¢
      const resultRows = await this.duckdb.query('SELECT COUNT(*) as count FROM RESULT');
      const newRowCount = this.safeToNumber(resultRows.get(0)?.count);

      if (newRowCount > originalRows) {
        summary.added = newRowCount - originalRows;
      } else if (newRowCount < originalRows) {
        summary.removed = originalRows - newRowCount;
      }

      // å¯¹äºç‰¹å®šæ“ä½œï¼Œæä¾›æ›´è¯¦ç»†çš„åˆ†æ
      for (const step of pipeline.steps) {
        switch (step.op) {
          case 'dedupe':
            // è®¡ç®—å»é‡åˆ é™¤çš„è¡Œæ•°
            const dedupeDropped = await this.calculateDedupeDropped(step, pipeline.dataset);
            summary.removed += dedupeDropped;
            break;

          case 'split':
            // åˆ—æ‹†åˆ†ä¼šå¢åŠ åˆ—ä½†ä¸å¢åŠ è¡Œ
            summary.modified += originalRows;
            break;

          case 'join':
            // JOIN å¯èƒ½å¢åŠ æˆ–å‡å°‘è¡Œæ•°
            const joinStats = await this.calculateJoinStats(step, pipeline.dataset);
            summary.added += joinStats.matched;
            summary.removed += joinStats.unmatched;
            break;
        }
      }
    } catch (error) {
      console.warn('Warning: Could not generate detailed summary:', error);
    }

    return summary;
  }

  /**
   * æ”¶é›†é—®é¢˜æ ·æœ¬
   */
  private async collectSamples(pipeline: Pipeline): Promise<PreviewResult['samples']> {
    const samples: PreviewResult['samples'] = {};

    try {
      // æ”¶é›†æ¯ä¸ªæ“ä½œçš„é—®é¢˜æ ·æœ¬
      for (const step of pipeline.steps) {
        switch (step.op) {
          case 'dedupe':
            samples.dropped = await this.collectDedupeSamples(step);
            break;

          case 'normalize':
            samples.failed = await this.collectNormalizationFailures(step);
            break;

          case 'join':
            samples.unmatched = await this.collectUnmatchedJoinKeys(step);
            break;
        }
      }
    } catch (error) {
      console.warn('Warning: Could not collect samples:', error);
    }

    return samples;
  }

  /**
   * è¯„ä¼°é£é™©
   */
  private async assessRisks(pipeline: Pipeline, originalRows: number, resultRows: number): Promise<string[]> {
    const risks: string[] = [];

    // è¡Œæ•°å˜åŒ–é£é™©
    const rowChangePercent = Math.abs(resultRows - originalRows) / originalRows * 100;
    if (rowChangePercent > 50) {
      risks.push(`âš ï¸ Row count changed by more than 50%: from ${originalRows} to ${resultRows} rows`);
    }

    // å…·ä½“æ“ä½œé£é™©è¯„ä¼°
    for (const step of pipeline.steps) {
      const stepRisks = await this.assessStepRisks(step, originalRows);
      risks.push(...stepRisks);
    }

    return risks;
  }

  /**
   * è¯„ä¼°å•ä¸ªæ­¥éª¤çš„é£é™©
   */
  private async assessStepRisks(step: Pipeline['steps'][0], _originalRows: number): Promise<string[]> {
    const risks: string[] = [];

    try {
      switch (step.op) {
        case 'normalize':
          // æ£€æŸ¥æ—¥æœŸ/é‡‘é¢è§£æå¤±è´¥ç‡
          if (step.dates) {
            for (const dateConfig of step.dates) {
              const failureRate = await this.calculateNormalizationFailureRate(dateConfig.col, 'date');
              if (failureRate > 0.3) {
                risks.push(`âš ï¸ Date column "${dateConfig.col}" parsing success rate is only ${((1 - failureRate) * 100).toFixed(1)}%`);
              }
            }
          }
          break;

        case 'dedupe':
          // æ£€æŸ¥å»é‡æ¯”ä¾‹
          const dedupeRate = await this.calculateDedupeRate(step);
          if (dedupeRate > 0.5) {
            risks.push(`âš ï¸ Deduplication will remove more than 50% of data (${(dedupeRate * 100).toFixed(1)}%)`);
          }
          break;

        case 'join':
          // æ£€æŸ¥JOINåŒ¹é…ç‡
          const matchRate = await this.calculateJoinMatchRate(step);
          if (matchRate < 0.7) {
            risks.push(`âš ï¸ Table join match rate is only ${(matchRate * 100).toFixed(1)}%`);
          }
          break;
      }
    } catch (error) {
      console.warn('Could not assess risks for step:', step, error);
    }

    return risks;
  }

  // è¾…åŠ©æ–¹æ³•å®ç°

  private async getModifiedColumns(pipeline: Pipeline): Promise<string[]> {
    const modified = new Set<string>();

    for (const step of pipeline.steps) {
      switch (step.op) {
        case 'normalize':
          step.dates?.forEach(d => modified.add(d.col));
          step.money?.forEach(m => modified.add(m.col));
          break;
        case 'split':
          step.into.forEach(col => modified.add(col));
          break;
        case 'clean':
          step.trims?.forEach(col => modified.add(col));
          step.normalizeSpace?.forEach(col => modified.add(col));
          step.replace?.forEach(r => modified.add(r.col));
          break;
      }
    }

    return Array.from(modified);
  }

  private async calculateDedupeDropped(step: Extract<Pipeline['steps'][0], { op: 'dedupe' }>, dataset: string): Promise<number> {
    try {
      const partitionBy = step.by.map(col => `"${col}"`).join(', ');
      const result = await this.duckdb.query(`
        SELECT SUM(cnt - 1) as dropped
        FROM (
          SELECT COUNT(*) as cnt
          FROM ${dataset}
          GROUP BY ${partitionBy}
          HAVING COUNT(*) > 1
        )
      `);
      return this.safeToNumber(result.get(0)?.dropped);
    } catch {
      return 0;
    }
  }

  private async calculateJoinStats(step: Extract<Pipeline['steps'][0], { op: 'join' }>, dataset: string): Promise<{ matched: number; unmatched: number }> {
    try {
      const joinConditions = Object.entries(step.on)
        .map(([leftCol, rightCol]) => `${dataset}."${leftCol}" = ${step.rightRef}."${rightCol}"`)
        .join(' AND ');

      const matchedResult = await this.duckdb.query(`
        SELECT COUNT(*) as count
        FROM ${dataset}
        INNER JOIN ${step.rightRef} ON ${joinConditions}
      `);

      const unmatchedResult = await this.duckdb.query(`
        SELECT COUNT(*) as count
        FROM ${dataset}
        LEFT JOIN ${step.rightRef} ON ${joinConditions}
        WHERE ${Object.values(step.on).map(col => `${step.rightRef}."${col}"`).join(' AND ')} IS NULL
      `);

      return {
        matched: this.safeToNumber(matchedResult.get(0)?.count),
        unmatched: this.safeToNumber(unmatchedResult.get(0)?.count),
      };
    } catch {
      return { matched: 0, unmatched: 0 };
    }
  }

  private async collectDedupeSamples(step: Extract<Pipeline['steps'][0], { op: 'dedupe' }>): Promise<any[]> {
    try {
      const partitionBy = step.by.map(col => `"${col}"`).join(', ');
      const result = await this.duckdb.query(`
        SELECT *
        FROM (
          SELECT *, ROW_NUMBER() OVER (PARTITION BY ${partitionBy} ORDER BY ${partitionBy}) as rn
          FROM a
        )
        WHERE rn > 1
        LIMIT 10
      `);
      return result.toArray();
    } catch {
      return [];
    }
  }

  private async collectNormalizationFailures(step: Extract<Pipeline['steps'][0], { op: 'normalize' }>): Promise<any[]> {
    const failures: any[] = [];

    if (step.dates) {
      for (const dateConfig of step.dates) {
        try {
          const result = await this.duckdb.query(`
            SELECT "${dateConfig.col}" as original_value, '${dateConfig.col}' as column_name
            FROM a
            WHERE "${dateConfig.col}" IS NOT NULL
              AND TRY_STRPTIME("${dateConfig.col}", '%Y-%m-%d') IS NULL
              AND TRY_STRPTIME("${dateConfig.col}", '%m/%d/%Y') IS NULL
              AND TRY_STRPTIME("${dateConfig.col}", '%d/%m/%Y') IS NULL
            LIMIT 5
          `);
          failures.push(...result.toArray());
        } catch (error) {
          console.warn('Could not collect normalization failures:', error);
        }
      }
    }

    return failures;
  }

  private async collectUnmatchedJoinKeys(step: Extract<Pipeline['steps'][0], { op: 'join' }>): Promise<any[]> {
    try {
      const joinConditions = Object.entries(step.on)
        .map(([leftCol, rightCol]) => `a."${leftCol}" = ${step.rightRef}."${rightCol}"`)
        .join(' AND ');

      const result = await this.duckdb.query(`
        SELECT ${Object.keys(step.on).map(col => `a."${col}"`).join(', ')}
        FROM a
        LEFT JOIN ${step.rightRef} ON ${joinConditions}
        WHERE ${Object.values(step.on).map(col => `${step.rightRef}."${col}"`).join(' AND ')} IS NULL
        LIMIT 10
      `);
      return result.toArray();
    } catch {
      return [];
    }
  }

  private async calculateNormalizationFailureRate(column: string, type: 'date' | 'money'): Promise<number> {
    try {
      const totalResult = await this.duckdb.query(`
        SELECT COUNT(*) as total FROM a WHERE "${column}" IS NOT NULL
      `);
      const total = this.safeToNumber(totalResult.get(0)?.total) || 1;

      let successQuery = '';
      if (type === 'date') {
        successQuery = `
          SELECT COUNT(*) as success FROM a
          WHERE "${column}" IS NOT NULL
            AND (TRY_STRPTIME("${column}", '%Y-%m-%d') IS NOT NULL
                OR TRY_STRPTIME("${column}", '%m/%d/%Y') IS NOT NULL
                OR TRY_STRPTIME("${column}", '%d/%m/%Y') IS NOT NULL)
        `;
      } else {
        successQuery = `
          SELECT COUNT(*) as success FROM a
          WHERE "${column}" IS NOT NULL
            AND TRY_CAST(REGEXP_REPLACE("${column}", '[^0-9.-]', '', 'g') AS DECIMAL) IS NOT NULL
        `;
      }

      const successResult = await this.duckdb.query(successQuery);
      const success = this.safeToNumber(successResult.get(0)?.success);

      return 1 - (success / total);
    } catch {
      return 0;
    }
  }

  private async calculateDedupeRate(step: Extract<Pipeline['steps'][0], { op: 'dedupe' }>): Promise<number> {
    try {
      const totalResult = await this.duckdb.query('SELECT COUNT(*) as total FROM a');
      const total = this.safeToNumber(totalResult.get(0)?.total) || 1;

      const partitionBy = step.by.map(col => `"${col}"`).join(', ');
      const uniqueResult = await this.duckdb.query(`
        SELECT COUNT(*) as unique_count
        FROM (SELECT DISTINCT ${partitionBy} FROM a)
      `);
      const unique = this.safeToNumber(uniqueResult.get(0)?.unique_count) || total;

      return (total - unique) / total;
    } catch {
      return 0;
    }
  }

  private async calculateJoinMatchRate(step: Extract<Pipeline['steps'][0], { op: 'join' }>): Promise<number> {
    try {
      const totalResult = await this.duckdb.query('SELECT COUNT(*) as total FROM a');
      const total = this.safeToNumber(totalResult.get(0)?.total) || 1;

      const joinConditions = Object.entries(step.on)
        .map(([leftCol, rightCol]) => `a."${leftCol}" = ${step.rightRef}."${rightCol}"`)
        .join(' AND ');

      const matchedResult = await this.duckdb.query(`
        SELECT COUNT(*) as matched
        FROM a
        INNER JOIN ${step.rightRef} ON ${joinConditions}
      `);
      const matched = this.safeToNumber(matchedResult.get(0)?.matched);

      return matched / total;
    } catch {
      return 0;
    }
  }

  /**
   * æ¸…ç†èµ„æº
   */
  async cleanup(): Promise<void> {
    await this.duckdb.cleanup();
  }

  /**
   * æ¸…ç†ä¸´æ—¶è¡¨å’Œè§†å›¾ä»¥é¿å…åç§°å†²çª
   * ä½¿ç”¨æœ€å°åŒ–æ¸…ç†é¿å…SQLè¯­æ³•é”™è¯¯
   */
  private async cleanupTempTables(): Promise<void> {
    try {
      console.log('ğŸ§¹ Cleaning up temporary objects...');

      // åªæ¸…ç†æœ€å…³é”®çš„ä¸´æ—¶å¯¹è±¡ï¼Œé¿å…SQLä¿ç•™å­—é—®é¢˜
      const criticalTempObjects = ['RESULT', 't1', 't2', 't3', 't4', 't5'];

      for (const objName of criticalTempObjects) {
        await this.dropObjectIfExists(objName);
      }

      console.log('âœ… Critical temporary objects cleaned up');
    } catch (error) {
      console.warn('âš ï¸ Cleanup warning (non-critical):', error);
    }
  }

  /**
   * æ ¹æ®å¯¹è±¡ç±»å‹å®‰å…¨åœ°åˆ é™¤ï¼ˆé¿å…è§†å›¾/è¡¨ç±»å‹ä¸åŒ¹é…çš„æŠ¥é”™æ—¥å¿—ï¼‰
   */
  private async dropObjectIfExists(name: string): Promise<void> {
    try {
      const typeRes = await this.duckdb.query(`
        SELECT table_type FROM information_schema.tables
        WHERE table_name = '${name.toUpperCase()}'
        LIMIT 1
      `);
      const rows = typeRes.toArray();
      if (!rows || rows.length === 0) {
        return;
      }
      const type = (rows[0].table_type || '').toString().toUpperCase();
      if (type.includes('VIEW')) {
        await this.duckdb.query(`DROP VIEW ${name}`);
      } else {
        await this.duckdb.query(`DROP TABLE ${name}`);
      }
    } catch (e) {
      // Swallow errors to keep cleanup non-blocking
    }
  }

  /**
   * åˆ›å»ºæ•°æ®å¤‡ä»½
   */
  async createBackup(datasetName: string): Promise<string> {
    const backupId = `backup_${datasetName}_${Date.now()}`;

    try {
      // åˆ›å»ºå¤‡ä»½è¡¨
      await this.duckdb.query(`CREATE TEMP TABLE ${backupId} AS SELECT * FROM ${datasetName}`);

      // å­˜å‚¨å¤‡ä»½ä¿¡æ¯
      const backups = this.backupStack.get(datasetName) || [];
      backups.push(backupId);
      this.backupStack.set(datasetName, backups);

      console.log(`âœ… Created backup: ${backupId} for dataset: ${datasetName}`);
      return backupId;
    } catch (error) {
      console.error('âŒ Failed to create backup:', error);
      throw new Error(`Failed to create backup for ${datasetName}`);
    }
  }

  /**
   * åº”ç”¨æ›´æ”¹ï¼ˆç”¨æˆ·ç¡®è®¤åæ›¿æ¢åŸæ•°æ®ï¼‰
   */
  async applyChanges(datasetName: string, pipeline: Pipeline): Promise<void> {
    try {
      // 0. æ¸…ç†ä¸´æ—¶è¡¨å’Œè§†å›¾
      await this.cleanupTempTables();

      // 1. åˆ›å»ºæ•°æ®å¤‡ä»½
      const backupId = await this.createBackup(datasetName);

      // 2. ç¼–è¯‘å®Œæ•´çš„DSLæ“ä½œ
      const sqls = this.compiler.compile(pipeline);

      // 3. æ‰§è¡Œæ“ä½œåºåˆ—
      console.log('ğŸ”„ Applying changes to original dataset...');
      await this.duckdb.executeSequence(sqls);

      // 4. ç”¨å¤„ç†åçš„ç»“æœæ›¿æ¢åŸæ•°æ®
      await this.duckdb.query(`CREATE OR REPLACE TEMP TABLE ${datasetName} AS SELECT * FROM RESULT`);

      // 5. æ¸…ç†ä¸´æ—¶è¡¨
      await this.duckdb.query('DROP TABLE IF EXISTS RESULT');

      console.log(`âœ… Successfully applied changes to dataset: ${datasetName}`);
      console.log(`ğŸ“¦ Backup available: ${backupId} (use rollback to revert)`);
    } catch (error) {
      console.error('âŒ Failed to apply changes:', error);
      throw new Error(`Failed to apply changes: ${error instanceof Error ? error.message : 'Unknown error'}`);
    }
  }

  /**
   * å›æ»šåˆ°ä¸Šä¸€ä¸ªç‰ˆæœ¬
   */
  async rollback(datasetName: string): Promise<boolean> {
    try {
      const backups = this.backupStack.get(datasetName);
      if (!backups || backups.length === 0) {
        console.warn('âš ï¸ No backups available for rollback');
        return false;
      }

      // è·å–æœ€æ–°çš„å¤‡ä»½
      const latestBackup = backups.pop();
      if (!latestBackup) {
        return false;
      }

      // æ£€æŸ¥å¤‡ä»½æ˜¯å¦å­˜åœ¨
      const backupExists = await this.checkTableExists(latestBackup);
      if (!backupExists) {
        console.error(`âŒ Backup table ${latestBackup} not found`);
        return false;
      }

      // æ¢å¤æ•°æ®
      await this.duckdb.query(`CREATE OR REPLACE TEMP TABLE ${datasetName} AS SELECT * FROM ${latestBackup}`);

      // æ¸…ç†å·²ä½¿ç”¨çš„å¤‡ä»½
      await this.duckdb.query(`DROP TABLE IF EXISTS ${latestBackup}`);

      // æ›´æ–°å¤‡ä»½æ ˆ
      this.backupStack.set(datasetName, backups);

      console.log(`âœ… Successfully rolled back dataset: ${datasetName}`);
      return true;
    } catch (error) {
      console.error('âŒ Rollback failed:', error);
      return false;
    }
  }

  /**
   * è·å–å¤‡ä»½å†å²
   */
  getBackupHistory(datasetName: string): string[] {
    return this.backupStack.get(datasetName) || [];
  }

  /**
   * æ¸…ç†æ‰€æœ‰å¤‡ä»½
   */
  async clearBackups(datasetName: string): Promise<void> {
    const backups = this.backupStack.get(datasetName) || [];

    for (const backupId of backups) {
      try {
        await this.duckdb.query(`DROP TABLE IF EXISTS ${backupId}`);
      } catch (error) {
        console.warn(`Warning: Could not drop backup ${backupId}:`, error);
      }
    }

    this.backupStack.delete(datasetName);
    console.log(`ğŸ§¹ Cleared all backups for dataset: ${datasetName}`);
  }

  /**
   * æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
   */
  private async checkTableExists(tableName: string): Promise<boolean> {
    try {
      const result = await this.duckdb.query(`
        SELECT COUNT(*) as count
        FROM information_schema.tables
        WHERE table_name = '${tableName.toUpperCase()}'
      `);
      return this.safeToNumber(result.get(0)?.count) > 0;
    } catch {
      return false;
    }
  }

  /**
   * è·å–æ•°æ®å˜æ›´æ‘˜è¦
   */
  async getChangesSummary(datasetName: string, pipeline: Pipeline): Promise<{
    originalRows: number;
    previewRows: number;
    affectedColumns: string[];
    riskLevel: 'LOW' | 'MEDIUM' | 'HIGH';
    risks: string[];
  }> {
    try {
      // è·å–åŸå§‹æ•°æ®è¡Œæ•°
      const originalInfo = await this.duckdb.getTableInfo(datasetName);

      // æ‰§è¡Œé¢„è§ˆè·å–å¤„ç†åè¡Œæ•°
      const previewSQLs = this.compiler.compileForPreview(pipeline, 10000); // ä½¿ç”¨æ›´å¤§æ ·æœ¬
      await this.duckdb.executeSequence(previewSQLs);
      const previewInfo = await this.duckdb.getTableInfo('RESULT');

      // åˆ†æå—å½±å“çš„åˆ—
      const affectedColumns = await this.getModifiedColumns(pipeline);

      // è¯„ä¼°é£é™©çº§åˆ«
      const risks = await this.assessRisks(pipeline, originalInfo.rowCount, previewInfo.rowCount);
      const riskLevel = this.calculateRiskLevel(originalInfo.rowCount, previewInfo.rowCount, risks.length);

      return {
        originalRows: originalInfo.rowCount,
        previewRows: previewInfo.rowCount,
        affectedColumns,
        riskLevel,
        risks,
      };
    } catch (error) {
      console.error('âŒ Failed to get changes summary:', error);
      throw error;
    }
  }

  /**
   * è®¡ç®—é£é™©çº§åˆ«
   */
  private calculateRiskLevel(originalRows: number, previewRows: number, riskCount: number): 'LOW' | 'MEDIUM' | 'HIGH' {
    // åŸºäºè¡Œæ•°å˜åŒ–ç™¾åˆ†æ¯”
    const changePercent = Math.abs(previewRows - originalRows) / originalRows * 100;

    if (changePercent > 50 || riskCount >= 3) {
      return 'HIGH';
    } else if (changePercent > 20 || riskCount >= 2) {
      return 'MEDIUM';
    } else {
      return 'LOW';
    }
  }
}
